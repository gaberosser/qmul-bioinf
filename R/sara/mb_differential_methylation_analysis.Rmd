---
title: "BMI1 and CHD7 in medulloblastoma primary lines"
subtitle: "Genome-wide DNA methylation analysis"
output: html_notebook
author: "Gabriel Rosser"
---

```{r setup, include=FALSE}
require("knitr")
# opts_knit$set(root.dir = normalizePath('..'))

knitr::opts_chunk$set(echo = TRUE)

require(limma)
require("ChAMP")
require("minfi")
require("wateRmelon")
require("data.table")
require(sva)
require(RColorBrewer)
require(openxlsx)

# this specifies the normalisation algorithm to use
norm.fun <- 'swan'

MVALUE_FN <- sprintf("m_values_1299_3021_%s.xlsx", norm.fun)
META_FN <- "metadata_1299_3021.csv"

source('../_settings.R')
```

# Analysing Sara's data
## Loading and preparing data

Check for the required input Excel file. Create it if necessary (from the raw idat files). We should only need to do this once.

```{r echo=FALSE}

if (!file.exists(MVALUE_FN) | !(file.exists(META_FN))) {
  writeLines(
    paste0("The input Excel file ", MVALUE_FN, " was not found. Computing from raw idats.")
  )
  
  source("../utils.R")
  
  MfromBeta <- function(beta) {
    log2(beta / (1 - beta))
  }
  
  split_path <- function(x) if (dirname(x)==x) x else c(basename(x),split_path(dirname(x)))
  
  get_idat_basenames <- function(idat.dir) {
    #' Get the basename of all idat files found recursively under the provided directory
    #' The basename is the full path, minus the trailing _Red.idat
    flist <- list.files(path = idat.dir, recursive = T)
    flist <- flist[grep('_Red.idat', flist)]
    
    # convert to basenames for loading
    basenames <- file.path(idat.dir, sub(pattern = "_Red.idat", "", flist))
  }
  
  
  process_idats <- function(
    in.files,
    snames,
    norm.fun=c('swan', 'bmiq', 'funnorm', 'noob', 'quantile', 'pbc', 'raw'),
    arraytype='EPIC'
  ) {
    norm.fun = match.arg(norm.fun)
    rgSet <- read.metharray(in.files, extended = T)
    colnames(rgSet) <- snames
    
    mset <- preprocessRaw(rgSet)
    detP <- detectionP(rgSet)
    
    # Load beta values (raw), then apply default ChAMP filtering
    beta.raw <- getBeta(mset, "Illumina")
    champLoad <- champ.filter(beta.raw, detP = detP, pd = NULL, arraytype = arraytype)
    beta.raw <- champLoad$beta
    
    if (norm.fun == 'raw') beta <- beta.raw
    
    if (norm.fun == 'swan') {
      mset.swan <- preprocessSWAN(rgSet, mSet = mset)
      beta.swan <- getBeta(mset.swan)
      beta <- beta.swan[rownames(beta.raw),]
    }
    
    if (norm.fun == 'bmiq') {
      beta <- champ.norm(beta = beta.raw, method = 'BMIQ', arraytype = arraytype, cores=4)
    }
    
    if (norm.fun == 'pbc') {
      beta <- champ.norm(beta = beta.raw, method = 'PBC', arraytype = arraytype)
    }
    
    if (norm.fun == 'funnorm') {
      grSet.funnorm <- preprocessFunnorm(rgSet)
      beta <- getBeta(grSet.funnorm)[rownames(beta.raw),]
    }
    
    if (norm.fun == 'quantile') {
      grSet.quantile <- preprocessQuantile(rgSet)
      beta <- getBeta(grSet.quantile)[rownames(beta.raw),]
    }
    
    if (norm.fun == 'noob') {
      mset.noob <- preprocessNoob(rgSet)
      beta <- getBeta(mset.noob)[rownames(beta.raw),]
    }
    
    return(list(beta.raw=beta.raw, beta=beta))
    
  }

# load data from raw

failed_filenames <- c(
  "202081130238/202081130238_R01C01"
)
samples <- c(
  'ICb1299_Scr', 
  'ICb1299_shBMI1', 
  'ICb1299_shCHD7', 
  'ICb1299_shBMI1CHD7', 
  'p62_3_shBmi1', 
  'p62_3_shChd7', 
  'p62_3_shB+C',
  'p62_3_Scr', 
  '3021_1_Scr', 
  '3021_1_shB', 
  '3021_1_shC', 
  '3021_1_shB+C',
  'S', 
  'B', 
  'C', 
  'B+C'
)

base.dirs <- c(
  file.path(data.dir.raid, 'methylation', '2017-09-19'),
  file.path(data.dir.raid, 'methylation', '2018-01-12'),
  file.path(data.dir.raid, 'methylation', '2018-03-19'),
  file.path(data.dir.raid, 'methylation', '2018-03-26'),
  file.path(data.dir.raid, 'methylation', '2018-04-09')
)

in.files <- NULL
snames <- NULL
batches <- NULL

for (b in base.dirs) {
  meta <- read.csv(file.path(b, 'sources.csv'))
  # set the rownames as filenames
  rownames(meta) <- paste(meta$Sentrix_ID, meta$Sentrix_Position, sep = '_')
  this_files <- get_idat_basenames(file.path(b, 'idat'))
  
  # reorder meta
  meta <- meta[basename(this_files),]
  
  # filter meta
  idx <- meta[, 'sample'] %in% samples
  
  # define file and sample names and add to list
  this_files <- this_files[idx]
  this_snames <- as.vector(meta[idx, 'sample'])
  this_batches <- as.vector(sapply(this_files, function(x){split_path(x)[4]}))
  
  in.files <- c(in.files, this_files)
  snames <- c(snames, this_snames)
  batches <- c(batches, this_batches)
}

# manually remove a failed sample
inds <- unlist(lapply(failed_filenames, function(x) grep(x, in.files)))
if (!is.null(inds)) {
  in.files <- in.files[-inds]
  snames <- snames[-inds]
  batches <- batches[-inds]
}

res <- process_idats(in.files, snames, norm.fun=norm.fun)
beta <- res$beta
beta.raw <- res$beta.raw

# simple metadata
meta <- data.frame(row.names = snames)

meta$cell_line <- '3021'
meta[grep('1299', rownames(meta)), 'cell_line'] <- '1299'
meta[grep('p62', rownames(meta)), 'cell_line'] <- '1299'

meta$batch <- batches

meta$condition <- 'Scr'
meta[grep('bmi1', rownames(meta), ignore.case = T), 'condition'] <- 'shBMI1'
meta[grep('shb', rownames(meta), ignore.case = T), 'condition'] <- 'shBMI1'

meta[grep('chd', rownames(meta), ignore.case = T), 'condition'] <- 'shCHD7'
meta[grep('shc', rownames(meta), ignore.case = T), 'condition'] <- 'shCHD7'

meta[grep('\\+', rownames(meta)), 'condition'] <- 'shBMI1shCHD7'
meta[grep('bmi1chd7', rownames(meta), ignore.case = T), 'condition'] <- 'shBMI1shCHD7'
meta[rownames(meta) == 'B', 'condition'] <- 'shBMI1'
meta[rownames(meta) == 'C', 'condition'] <- 'shCHD7'

m <- MfromBeta(beta)

# save M data to Excel file.
write.xlsx(m, MVALUE_FN, colNames = T, rowNames = T)
# save metadata to CSV file.
write.csv(meta, META_FN)

} else {
  
  BetafromM <- function(m) {
    (2 ** m) / (1 + 2 ** m)
  }
  
  writeLines(
    paste0("Loading pre-computed M data from ", MVALUE_FN),
    paste0("Loading pre-computed metadata from ", META_FN)
  )
  m <- read.xlsx(MVALUE_FN, rowNames = T)
  beta <- BetafromM(m)
  meta <- read.csv(META_FN, row.names = 1)
}
```

Run a few exploratory checks.

```{r}

densityPlot(as.matrix(beta), sampGroups = meta$batch, ylim = c(0,7))
densityPlot(as.matrix(beta), sampGroups = meta$cell_line, ylim = c(0,7))

pal <- brewer.pal(8,"Dark2")
plotMDS(m, top=NULL, col=pal[factor(meta$batch)])
legend("topright", legend=levels(factor(meta$batch)), text.col=pal, bg="white")

plotMDS(m[, meta$cell_line == '1299'], top=NULL, col=pal[factor(meta[meta$cell_line == '1299', 'batch'])])
legend("topright", legend=levels(factor(meta[meta$cell_line == '1299', 'batch'])), text.col=pal, bg="white")

ix <- meta$cell_line == '3021'
plotMDS(m[, ix], top=NULL, col=pal[factor(meta[ix, 'batch'])])
legend("topright", legend=levels(factor(meta[ix, 'batch'])), text.col=pal, bg="white")

```

## Differential methylation

Now let's identify differentially methylated probes (DMPs). We'll carry out a separate analysis for each of the two cell lines (1299 and 3021). 

Before searching for DMPs, we'll run two filtering steps:

1. Filtering based on the range of M values and requiring a minimum variation across the samples.
2. Requiring consistency within each of the experimental groups, such that the variation in M value cannot exceed a threshold.

If we don't do this, our p values will all come out non-significant following the correction for multiple hypothesis testing.

```{r}
minimum_range <- 1.
maximum_variation_within_group <- 5.
# this is the FDR cutoff, only used for reporting purposes (all DMPs with unadjusted P < 0.05 are exported)
alpha <- 0.05

data.filt <- list()
meta.filt <- list()

for (cl in c('3021', '1299')) {

  writeLines(paste0("Cell line ", cl))
  this.meta <- droplevels(meta[meta$cell_line == cl,])
  this.m <- m[, rownames(this.meta)]
  
  # Filter 1: minimum range
  
  n_before <- nrow(this.m)
  rg <- apply(this.m, 1, range)
  rg <- rg[2,] - rg[1,]
  ix <- rg > minimum_range
  
  hist(rg, 40, xlab='M value range', main=paste0(cl, ' M value range'))
  abline(v=minimum_range, col='red', lty=2)
  
  this.m <- this.m[ix,]
  n_after <- nrow(this.m)
  writeLines(
    sprintf(
      "Filtering based on a minimum range threshold of %.2f results in the number of probes going from %d to %d (removing %d)",
      minimum_range,
      n_before,
      n_after,
      n_before - n_after
    )
  )
  
  condition <- factor(this.meta$condition)
  batch <- make.names(factor(this.meta$batch))
  
  # Filter 2: Maximum variation
  # this should be possible to do efficiently using group_by from dplyr, but I hate R and it hates me.
  group_probes <- list()
  for (cnd in levels(condition)) {
    n_before <- nrow(this.m)
    this.group.m <- this.m[,condition == cnd]
    rg <- apply(this.group.m, 1, range)
    rg <- rg[2,] - rg[1,]
    ix <- rg < maximum_variation_within_group
    this.group.m <- this.group.m[ix,]
    n_after <- nrow(this.group.m)
    writeLines(
      sprintf(
        "Filtering based on a maximum inter-group threshold of %.2f results in the number of probes in group %s going from %d to %d (removing %d)",
        maximum_variation_within_group,
        cnd,
        n_before,
        n_after,
        n_before - n_after
      )
    )
    group_probes[[cnd]] <- rownames(this.group.m)
  }
  
  # now eliminate any probes that were removed
  common_probes = Reduce(intersect, group_probes)
  n_before <- nrow(this.m)
  this.m <- this.m[common_probes,]
  n_after <- nrow(this.m)
  writeLines(
    sprintf(
      "After the second stage of filtering (inter-group variation), we reduced the number of probes from %d to %d (removed %d)",
      n_before,
      n_after,
      n_before - n_after
    )
  )
  data.filt[[cl]] <- this.m
  meta.filt[[cl]] <- this.meta
}

```

Now we  proceed to run DMP analysis *without* batch correction

```{r dmp_no_batch, echo=F}
dmps <- list()

for (cl in c('3021', '1299')) {
  dmps[[cl]] <- list()
  this.m <- data.filt[[cl]]
  this.meta <- meta.filt[[cl]]
  
  design <- model.matrix(~0 + condition + batch)
  fit <- lmFit(this.m, design)
  contrasts <- makeContrasts(
    conditionshBMI1-conditionScr, 
    conditionshCHD7-conditionScr, 
    conditionshBMI1shCHD7-conditionshBMI1, 
    conditionshBMI1shCHD7-conditionshCHD7, 
    conditionshBMI1shCHD7-conditionScr, 
    levels=design
  )

  fit2 <- contrasts.fit(fit, contrasts)
  fit2 <- eBayes(fit2, trend = T, robust = T)
  
  for (i in seq(ncol(contrasts))) {
    ttl <- colnames(contrasts)[i]
    ttl <- gsub(pattern = "condition", replacement = '', x = ttl)
    this_res <- topTable(fit2, coef = i, number = Inf)
    this_res <- this_res[this_res$P.Value < 0.05,]
    dmps[[cl]][[ttl]] <- this_res
    writeLines(sprintf(
      "Comparison %s: %d DMPs with FDR < %.2f",
      ttl,
      sum(this_res$adj.P.Val < alpha),
      alpha
    ))
  }
  out_fn <- paste0("dmps_", cl, ".xlsx")
  write.xlsx(dmps[[cl]], out_fn, colNames = T, rowNames = T)
  writeLines(
    sprintf(
      "Wrote the DMP results to file %s", 
      out_fn
    )
  )
  
}
  
```

It will turn out that batch correction isn't very helpful, but the code below applies it as suggested by the authors.

``` {r dmp_with_batch, echo=F, eval=F}
dmps.sv <- list()

for (cl in c('3021', '1299')) {
  dmps.sv[[cl]] <- list()
  this.m <- data.filt[[cl]]
  this.meta <- meta.filt[[cl]]
  
  mod <- model.matrix(~0+condition+batch, data=this.meta)
  mod_null <- model.matrix(~0+batch, data=this.meta)
  # get SVA to estimate the number of latent variables
  n.sv <- num.sv(as.matrix(this.m), mod, method='leek')
  svobj <- sva(as.matrix(this.m), mod, mod_null, n.sv=n.sv)
  
  mod.Sv <- cbind(mod, svobj$sv)
  colnames(mod.Sv) <- c(colnames(design), "sva")
  
  fit <- lmFit(this.m, mod.Sv)
  contrasts <- makeContrasts(
    conditionshBMI1-conditionScr, 
    conditionshCHD7-conditionScr, 
    conditionshBMI1shCHD7-conditionshBMI1, 
    conditionshBMI1shCHD7-conditionshCHD7, 
    conditionshBMI1shCHD7-conditionScr, 
    levels=mod.Sv
  )

  fit2 <- contrasts.fit(fit, contrasts)
  fit2 <- eBayes(fit2, trend = T, robust=T)
  
  for (i in seq(ncol(contrasts))) {
    ttl <- colnames(contrasts)[i]
    ttl <- gsub(pattern = "condition", replacement = '', x = ttl)
    this_res <- topTable(fit2, coef = i, number = Inf)
    this_res <- this_res[this_res$P.Value < 0.05,]
    dmps.sv[[cl]][[ttl]] <- this_res
    writeLines(sprintf(
      "BATCH CORRECTED Comparison %s: %d DMPs with FDR < %.2f",
      ttl,
      sum(this_res$adj.P.Val < alpha),
      alpha
    ))
  }
  out_fn <- paste0("dmps_sva_", cl, ".xlsx")
  write.xlsx(dmps.sv[[cl]], out_fn, colNames = T, rowNames = T)
  writeLines(
    sprintf(
      "Wrote the DMP results to file %s", 
      out_fn
    )
  )

}

```

Now let's generate the volcano plots.

```{r}
for (cl in c('3021', '1299')) {
  this.dmps <- dmps[[cl]]
  the_names <- names(this.dmps)
  for (cmp in the_names) {
    ttl <- paste(cl, cmp, sep = ' ')
    x <- this.dmps[[cmp]]
    absx_max <- ceiling(max(abs(x$logFC)))
    plot(x$logFC, -log10(x$adj.P.Val), main=ttl, xlim=c(-absx_max, absx_max))
  }
}

```

The 3021 line results seem to show evidence of dependence (i.e. a functional link between log fold change and adjusted P value). Here are a few forum posts discussing this:

- https://support.bioconductor.org/p/111776/
- https://support.bioconductor.org/p/95197/
- https://support.bioconductor.org/p/57445/

In summary: the estimate of prior degrees of freedom is inifinity, meaning that all genes end up with the same estimated dispersion, hence P value is a function of log fold change. We can (partially) fix this by ensuring we run `eBayes()` with `robust=T` and `trend=T`.

# Analysing the _Cavalli et al._ cohort data
## Loading and preparing the data

The authors have provided a pre-normalised matrix of beta values. We'll start with this, to avoid the need to normalise hundreds of samples. We'll load just the group 4 samples.

```{r, cavalli_load, echo=F}
in.dir <- file.path(data.dir.raid, 'methylation', 'GSE85212')
meta_fn <- file.path(in.dir, 'sources.csv')
beta_fn <- file.path(in.dir, 'beta', 'GSE85212_Methylation_763samples_SubtypeStudy_TaylorLab_beta_values.txt.gz')

meta.cavalli <- read.csv(meta_fn, header=T, row.names = 1)
ix <- meta.cavalli$subgroup == 'Group4'
meta.cavalli <- meta.cavalli[ix,]
load_cols <- c(1, which(ix) + 1)
beta.cavalli <- fread(cmd = sprintf("zcat %s", beta_fn), select = load_cols, data.table = F)

# set row names and drop the unneeded col
rownames(beta.cavalli) <- beta.cavalli[,1]
beta.cavalli$V1 <- NULL
m.cavalli <- logit2(beta.cavalli)

meta.cavalli <- droplevels(meta.cavalli)

```

A few exploratory plots

```{r, cavalli_explore, echo=F}

densityPlot(as.matrix(beta.cavalli), sampGroups = meta.cavalli$subtype_formatted, ylim = c(0, 7))

# the MDS plot seems to take forever, so disabling for now
if (F) {
  pal <- brewer.pal(3,"Dark2")
  plotMDS(m.cavalli, top=NULL, col=pal[factor(meta.cavalli$subtype_formatted)])
  legend("topright", legend=levels(factor(meta.cavalli$batch)), text.col=pal, bg="white")
}

```

## Differential methylation

The main comparison of interest here is 'signature vs no signature' in different settings:

- All group 4
- Group 4 alpha
- Group 4 beta
- Group 4 gamma

We'll run this in `limma` as before, supplying the subtype and presence of signature as variables to the model matrix and using contrasts to pull out the relevant results. All parameters will be kept the same as before.

Start by filtering the data. We only apply step 1 here (require a minimum range across all samples), as step 2 (imposing a maximum intra-group variation) discards an unacceptable number of probes. This is probably due to the larger size of the groups.

```{r cavalli_filt, echo=F}
minimum_range <- 1.
maximum_variation_within_group <- 5.

# Filter 1: minimum range

n_before <- nrow(m.cavalli)
rg <- apply(m.cavalli, 1, range)
rg <- rg[2,] - rg[1,]
ix <- rg > minimum_range

hist(rg, 40, xlab='M value range', main=paste0(cl, ' M value range'))
abline(v=minimum_range, col='red', lty=2)

m.cavalli.filt <- m.cavalli[ix,]
n_after <- nrow(m.cavalli.filt)
writeLines(
  sprintf(
    "Filtering based on a minimum range threshold of %.2f results in the number of probes going from %d to %d (removing %d)",
    minimum_range,
    n_before,
    n_after,
    n_before - n_after
  )
)

condition <- factor(meta.cavalli$subtype_formatted)

# Filter 2: Maximum variation
# Disabled since it results in a very large loss of probes.
if (F) {
  # this should be possible to do efficiently using group_by from dplyr, but I hate R and it hates me.
  group_probes <- list()
  for (cnd in levels(condition)) {
    n_before <- nrow(m.cavalli.filt)
    this.group.m <- m.cavalli.filt[,condition == cnd]
    rg <- apply(this.group.m, 1, range)
    rg <- rg[2,] - rg[1,]
    ix <- rg < maximum_variation_within_group
    this.group.m <- this.group.m[ix,]
    n_after <- nrow(this.group.m)
    writeLines(
      sprintf(
        "Filtering based on a maximum inter-group threshold of %.2f results in the number of probes in group %s going from %d to %d (removing %d)",
        maximum_variation_within_group,
        cnd,
        n_before,
        n_after,
        n_before - n_after
      )
    )
    group_probes[[cnd]] <- rownames(this.group.m)
  }
  
  # now eliminate any probes that were removed
  common_probes = Reduce(intersect, group_probes)
  n_before <- nrow(m.cavalli.filt)
  m.cavalli.filt <- m.cavalli.filt[common_probes,]
  n_after <- nrow(m.cavalli.filt)
  writeLines(
    sprintf(
      "After the second stage of filtering (inter-group variation), we reduced the number of probes from %d to %d (removed %d)",
      n_before,
      n_after,
      n_before - n_after
    )
  )

}

```


```{r, cavalli_dm, echo=F}
  subtype <- meta.cavalli$subtype_formatted
  signature <- meta.cavalli$CHD7_signature
  groups <- as.factor(paste(subtype, as.character(signature), sep='.'))
  
  design <- model.matrix(~0 + groups)
  colnames(design) <- levels(groups)
  cont.matrix <- makeContrasts(
    alpha=Group4_alpha.1-Group4_alpha.0,
    beta=Group4_beta.1-Group4_beta.0,
    gamma=Group4_gamma.1-Group4_gamma.0,
    all=(Group4_alpha.1+Group4_beta.1+Group4_gamma.1)/3-(Group4_alpha.0+Group4_beta.0+Group4_gamma.0)/3,
    levels=design
  )
  fit <- lmFit(m.cavalli.filt, design)
  fit2 <- contrasts.fit(fit, cont.matrix)
  fit2 <- eBayes(fit2, trend = T, robust = T)

  results <- decideTests(fit2, p.value = alpha)
  vennDiagram(results)
  
  dmps.cavalli <- list()
  for (cont in colnames(cont.matrix)) {
    this.res <- topTable(fit2, coef=cont, number=Inf)
    dmps.cavalli[[cont]] <- this.res[this.res$P.Value < 0.05,]
    writeLines(sprintf(
      "Comparison %s: %d DMPs with FDR < %.2f",
      cont,
      sum(this.res$adj.P.Val < alpha),
      alpha
    ))
  }
  
  out_fn <- "dmps_cavalli.xlsx"
  write.xlsx(dmps.cavalli, file = out_fn, colnames = T, rowNames = T)
  
```

Let's check the level of methylation in the DM probes, as a sanity check.

```{r cavalli_dm_plots}
  for (cont in names(dmps.cavalli)) {
    probes <- head(rownames(dmps.cavalli[[cont]]), 4)
    df <- beta.cavalli[probes,]
    df_melt <- melt(as.matrix(df))
    colnames(df_melt) <- c('probe', 'sample', 'beta')
    # add column with subtype, signature
    df_melt$subtype = meta.cavalli[df_melt$sample, 'subtype_formatted']
    df_melt$signature = as.factor(meta.cavalli[df_melt$sample, 'CHD7_signature'])
    plt <- ggplot(df_melt) + geom_boxplot(aes(x=subtype, y=beta, fill=signature)) + facet_wrap(~as.factor(probe)) + ggtitle(sprintf("DMPs in %s", cont))
    plot(plt)
  }
```


Just for information, here's a different way to approach the same comparison. The design matrix and contrasts differ, but the results are exactly the same. Have disabled evaluation for now.
  
``` {r, cavalli_dm_approach_2, echo=F, eval=F}
  # baseline (intercept) is alpha with no signature, all other coefs are given as a difference
  design.2 <- model.matrix(~subtype+subtype:signature)
  colnames(design.2) <- c(
    'baseline',
    'plus_beta',
    'plus_gamma',
    'plus_alpha_sign',
    'plus_beta_sign',
    'plus_gamma_sign'
  )
  
  cont.matrix.2 <- makeContrasts(
    alpha=plus_alpha_sign,
    beta=plus_beta_sign,
    gamma=plus_gamma_sign,
    all=(plus_alpha_sign+plus_beta_sign+plus_gamma_sign)/3,
    levels=design.2
  )

  fit.2 <- lmFit(m.cavalli.filt, design.2)
  fit2.2 <- contrasts.fit(fit.2, cont.matrix.2)
  fit2.2 <- eBayes(fit2.2, trend = T, robust = T)
  
  dmps.cavalli.2 <- list()
  for (cont in colnames(cont.matrix.2)) {
    this.res <- topTable(fit2.2, coef=cont, number=Inf)
    dmps.cavalli.2[[cont]] <- this.res[this.res$P.Value < 0.05,]
  }
```

