---
title: "Analysing the DNA methylation data from paired GBM samples"
output: html_notebook
---

This piece of code ensures that the working directory for all subsequent calls is the required root directory for the project.

```{r setup}
require("knitr")
opts_knit$set(root.dir = normalizePath('..'))
```

Load some required packages.

```{r, message=FALSE, warning=FALSE, results="hide"}
source('io/output.R')
source('_settings.R')
source("utils.R")
library("ChAMP")
library("minfi")
library("wateRmelon")
```

We will need to convert between $\beta$ values and M values. The relationship is

$$
M = \log_2\left(\dfrac{\beta}{1 - \beta}\right)
$$
```{r}
MfromBeta <- function(beta) {
  log2(beta / (1 - beta))
}
```

We'll be using the `ChAMP` package to extract methylation beta values from the Illumina raw data files (`*.idat`).

Start by defining the input directory. This must contain a single `.csv` file in the standard Illumina sample sheet format. Data from different chips are located in subdirectories with the name of the chip. *All* of the samples listed will be loaded. We don't want all of them, so we will run the first few steps manually. 

Load data, filtering by beadcount to keep only the relevant probes (this can't be done downstream as it relies on the raw red/green data and we only use beta/M values beyond this point). For beadcount filtering, the `ChAMP` implementation removes those probes for which >5% of records have a beadcount of <3. In our small sample case, this is the same as requiring that *no single sample* has <3 beads.

```{r}
base.dir <- file.path(data.dir.raid, 'methylation', '2016-12-19_ucl_genomics')
in.dir <- file.path(base.dir, 'idat')

# Carry out filtering on the targets sheet before loading data
targets <- read.metharray.sheet(in.dir)
targets <- targets[!grepl('icb', targets$Sample_Name, ignore.case = T),]
targets <- targets[grepl('018|019|031', targets$Sample_Name),]
targets$Sample_Name <- c(
  "GBM018",
  "GBM019",
  "GBM031",
  "Dura018",
  "Dura019",
  "Dura031"
)
targets$Sample_Group <- c(
  rep("GBM", 3), rep("iNSC", 3)
)

rgSet <- read.metharray.exp(targets = targets, extended=TRUE)
# rgSet@annotation <- c(array="IlluminaHumanMethylationEPIC",annotation="ilmn10.hg19")
rgSet@annotation <- c(array="IlluminaHumanMethylationEPIC",annotation="ilm10b2.hg19")

bc <- beadcount(rgSet)
keep.idx <- which(as.vector(rowSums(is.na(bc)) == 0))
bc <- na.omit(bc)

mset <- preprocessRaw(rgSet)
mset <- mset[rownames(bc),]

detP <- detectionP(rgSet)
detP <- detP[rownames(bc),]

pd <- pData(rgSet)

beta.raw <- getBeta(mset, "Illumina")
# there is a method `getM` designed for this, but it seems inconsistent
m.raw <- MfromBeta(beta.raw)
colnames(beta.raw) <- pd[colnames(beta.raw), 'Sample_Name']
```

Now we filter the data using the default ChAMP process. This has a few steps:
 - Remove any samples with too many failed probes
 - Remove probes with a poor detection probability
 - Remove some probes that other research has shown to be poor
 - Remove X, Y chromosome probes.

```{r}
myLoad <- champ.filter(beta.raw, detP = detP, pd = pd, arraytype = "EPIC")
```

Now we have loaded the data, we should normalise it. There are several options: BMIQ, SWAN, PBC and FunctionalNormalize. The latter is *not* supported for EPIC arrays.

```{r}
beta.bmiq <- champ.norm(beta = myLoad$beta, method = 'BMIQ', arraytype = "EPIC", cores=4)
m.bmiq <- MfromBeta(beta.bmiq)
```

```{r}
beta.pbc <- champ.norm(beta = myLoad$beta, method = 'PBC', arraytype = "EPIC")
m.pbc <- MfromBeta(beta.pbc)
```

```{r}
mset.swan <- preprocessSWAN(rgSet, mSet = mset)
beta.swan <- getBeta(mset.swan)
beta.swan <- beta.swan[rownames(myLoad$beta),]
colnames(beta.swan) <- pd[colnames(beta.swan), 'Sample_Name']
m.swan <- MfromBeta(beta.swan)
```

```{r}
grSet.funnorm <- preprocessFunnorm(rgSet)
beta.funnorm <- getBeta(grSet.funnorm)[rownames(myLoad$beta),]
m.funnorm <- MfromBeta(beta.funnorm)
```

Since that process is fairly time-consuming, we'll save the beta values to CSV.

```{r, message=FALSE, warning=FALSE}
outDir <- file.path(base.dir, 'beta')
dir.create(outDir, showWarnings = FALSE)
write.csv(beta.raw, file = file.path(outDir, "beta_raw.csv"))
write.csv(beta.bmiq, file = file.path(outDir, "beta_bmiq.csv"))
write.csv(beta.swan, file = file.path(outDir, "beta_swan.csv"))
write.csv(beta.pbc, file = file.path(outDir, "beta_pbc.csv"))
write.csv(beta.funnorm, file = file.path(outDir, "beta_funnorm.csv"))
```

Now we load annotations for the probes. In particular, we want the chromosome and chromosomal coordinate, but we also get any associated genes and a very approximate categorical distance from the TSS.

*NB: Illumina released an updated version of the manifest (b3) on 17th Apr 2017, but this hasn't been supplied in Bioconductor yet. Keep an eye out for it!*

```{r}
library(IlluminaHumanMethylationEPICanno.ilm10b2.hg19)
head(IlluminaHumanMethylationEPICanno.ilm10b2.hg19::Locations)
head(IlluminaHumanMethylationEPICanno.ilm10b2.hg19::Other)
```

We could test for individual probes that differ between pairs of samples (differentially methylated probes, DMP). However, this seems less compelling than seeking out _regions_ of high methylation (differentially methylated regions, DMR). DMR "works" because probes that are close in genomic distance are correlated. 

There are a few available methods:

* Bumphunting. Eliminate batch effects, run a regression to determine coefficients for the contrast of interest, define a symmetric threshold for the coefficients, identify regions where all probes exceed it, permutation test. The implementation is designed for large datasets.
* DMRforPairs. More heuristic. Define minimum number of probes, maximum distance between them and minimum absolute methylation then use Mann-Whitney to run statistical test of each identified cluster. Designed for unique samples.
 
In fact, we want something that combines both and incorporates a paired sample statistical model. In bumphunting, this would be useful in the first step (building a linear model and parametrising it). Does that make sense?
 
Start with DMRForPairs. Setup the input variables.

```{r}
library(DMRforPairs)
beta.v <- beta.bmiq
m.v <- MfromBeta(beta.v)

target_id <- rownames(beta.v)
gene_classes <- IlluminaHumanMethylationEPICanno.ilm10b2.hg19::Other[target_id, 'UCSC_RefGene_Group']
gene_symbol <- IlluminaHumanMethylationEPICanno.ilm10b2.hg19::Other[target_id, 'UCSC_RefGene_Name']
island_classes <- IlluminaHumanMethylationEPICanno.ilm10b2.hg19::Islands.UCSC[target_id, 'Relation_to_Island']

chr <- IlluminaHumanMethylationEPICanno.ilm10b2.hg19::Locations[target_id, 'chr']
pos <- IlluminaHumanMethylationEPICanno.ilm10b2.hg19::Locations[target_id, 'pos']

```

Let's play around with it first to understand the algorithm.

```{r}
# debug: limit to a single chromosome
idx <- chr == "chr1"
tid <- target_id[idx]
gcs <- gene_classes[idx]
gs <- gene_symbol[idx]
ics <- island_classes[idx]

ch <- chr[idx]
po <- pos[idx]

# merge classes (TSS, island, body)
classes <- merge_classes(gcs, ics, recode = 1, sep = ';')
rownames(classes$pclass) <- tid
rownames(classes$pclass_recoded) <- tid

b <- beta.v[idx,]
m <- m.v[idx,]

regions <- regionfinder(tid, ch, po, classes$pclass_recoded, 
                        classes$no.pclass, classes$u_pclass, 200, m, 
                        b, n_min = 4, gs = gs)
probes <- regions$perprobe
m <- regions$valid.m
b <- regions$valid.beta
n <- dim(m)[2]  # number of samples
dMth = 1.4  # minimum difference in M required to declare a bump
ID = data.frame(regions$boundaries$regionID)
```


The algorithm requires us to specify two key parameters: $d_{\text{max}}$ is the maximum accepted distance between neighbouring probes for membership in a cluster and $n_{\text{min}}$ is the minimum number of probes in a cluster. We can tune these beforehand by parameter sweeping using `tune_parameters`.

```{r}
parameters <- expand.grid(min_distance = c(200, 300, 400), min_n = c(4, 6, 8))
sweep.results <- tune_parameters(
  parameters = parameters,
  classes_gene = gene_classes,
  classes_island = island_classes,
  targetID = target_id,
  chr = chr,
  position = pos,
  m.v = m.v,
  beta.v = beta.v,
  gs = gene_symbol,
  do.parallel = -1,
  recode=2  # for speed - puts all probe classes together
)
```

```{r}
d_max <- matrix(sweep.results[,'min_distance'], nrow=3)
n_min <- matrix(sweep.results[,'min_n'], nrow=3)
n_regions <- matrix(sweep.results[,'n.regions'], nrow=3)
prop_probes <- matrix(
  sweep.results[,'n.valid.probes'] / sweep.results[,'n.probes.included'],
  nrow=3)
xi = 1:ncol(d_max)
yi = 1:nrow(d_max)
centres <- expand.grid(yi, xi)
par(mar = c(2,7,4,2))
image(xi, yi, t(n_regions),
      col = rev(terrain.colors(25)),
      xaxt = 'n',
      yaxt = 'n',
      xlab = '', 
      ylab = '',
      ylim = c(max(yi) + 0.5, min(yi) - 0.5)
      )
# title(xlab='n_min', ylab='d_max')
text(centres[,2], centres[,1], n_regions, col="black")
mtext(n_min[1,], at=1:ncol(n_regions))
mtext(d_max[,1], at=1:nrow(n_regions), side=2, padj=-1)
mtext("n_min", side=3, padj=-2.)
mtext("d_max", side=2, padj=-3.)
```

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).
